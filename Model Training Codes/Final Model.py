# -*- coding: utf-8 -*-
"""Final Model Training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16zZeM4yqiDsKBWSoyZgiXLc4K3I_J0Gj
"""

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.backend import concatenate
from re import X
import cv2
from PIL import Image
import os
import numpy as np
import pandas as pd
import pickle
import tensorflow as tf
from os import listdir
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout, Flatten,Concatenate,BatchNormalization,Embedding,Activation
from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D,Conv2D
from tensorflow.keras.callbacks import ModelCheckpoint
from os.path import isfile, join
import numpy as np
from tensorflow.keras import Sequential
from tensorflow.keras.models import load_model
from tensorflow.keras.optimizers import Adam
import numpy as np
import pandas as pd

import tensorflow as tf

from tensorflow import feature_column
from tensorflow.keras import layers

height=128
width=128
path1='/content/drive/My Drive/bounding box/real/'
realfiles1 = sorted([ f for f in listdir(path1) if isfile(join(path1,f)) ])
#print(realfiles1)
data=[]
labels=[]
###########################################################################
for i in realfiles1:
  try:
    path1='/content/drive/My Drive/bounding box/real/'+i
    img=cv2.imread(path1)
    img=cv2.resize(img,(height,width))
    data.append(img)
    labels.append(0)
  except:
    pass

path2='/content/drive/My Drive/bounding box/fake/'
realfiles2 = sorted([ f for f in listdir(path2) if isfile(join(path2,f)) ])
#print(realfiles2)

for i in realfiles2:
  try:
    path2='/content/drive/My Drive/bounding box/fake/'+i
    img=cv2.imread(path2)
    img=cv2.resize(img,(height,width))
    data.append(img)
    labels.append(1)
  except:
    pass
data=np.array(data)
labels=np.array(labels)
###########################################################################
path3='/content/drive/My Drive/face/real/'
realfiles3= sorted([ f for f in listdir(path3) if isfile(join(path3,f)) ])
#print(realfiles3)
data1=[]
labels1=[]
for i in realfiles3:
  try:
    path3='/content/drive/My Drive/face/real/'+i
    img=cv2.imread(path3)
    img=cv2.resize(img,(height,width))
    data1.append(img)
    labels1.append(0)
  except:
    pass
path4='/content/drive/My Drive/face/fake/'
realfiles4= sorted([ f for f in listdir(path4) if isfile(join(path4,f)) ])
for i in realfiles4:
  try:
    path4='/content/drive/My Drive/face/fake/'+i
    img=cv2.imread(path4)
    img=cv2.resize(img,(height,width))
    data1.append(img)
    labels1.append(1)
  except:
    pass
data1=np.array(data1)
labels1=np.array(labels1)
#########################################################################
path5='/content/drive/My Drive/context/real/'
realfiles5= sorted([ f for f in listdir(path5) if isfile(join(path5,f)) ])
#print(realfiles5)
data2=[]
labels2=[]
for i in realfiles5:
  try:
    path5='/content/drive/My Drive/context/real/'+i
    img=cv2.imread(path5)
    img=cv2.resize(img,(height,width))
    data2.append(img)
    labels2.append(0)
  except:
    pass
path6='/content/drive/My Drive/context/fake/'
realfiles6= sorted([ f for f in listdir(path6) if isfile(join(path6,f)) ])
#print(realfiles6)
for i in realfiles6:
  try:
    path6='/content/drive/My Drive/context/fake/'+i
    img=cv2.imread(path6)
    img=cv2.resize(img,(height,width))
    data2.append(img)
    labels2.append(1)
  except:
    pass
data2=np.array(data2)
labels2=np.array(labels2)
##########################################################################

model1=load_model('/content/drive/My Drive/bound_model2.h5')
model2=load_model('/content/drive/My Drive/face_model2.h5')
model3=load_model('/content/drive/My Drive/context_model2.h5')

df=pd.DataFrame(columns=['Features','label'])
df['label']=labels

ip=[]
for i in range(0,2020):
    a=data[i]
    #print(a.shape)
    a=np.expand_dims(a, axis=0)
    pred1 = model1.predict(a)
    
    b=data1[i]
    b=np.expand_dims(b, axis=0)
    pred2 = model2.predict(b)
    
    c=data2[i]
    c=np.expand_dims(c, axis=0)
    pred3 = model3.predict(c)
    combined=np.concatenate([pred1,pred2,pred3])
    ip.append(combined)

df['Features']=ip

print(df)

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1,activation='sigmoid')
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

train,test=train_test_split(df,test_size=0.1,random_state=42,shuffle=True)

print("Train shape(df) :",train.shape)
print("Test shape(df) :",test.shape)

m1=np.stack(train['Features'].values)
m2=np.stack(train['label'].values)

checkpoint = ModelCheckpoint('/content/drive/My Drive/final_model.h5',
    monitor='accuracy',
    save_best_only=True,
    verbose=1)
model =model.fit(m1,m2,epochs=60,callbacks=[checkpoint])